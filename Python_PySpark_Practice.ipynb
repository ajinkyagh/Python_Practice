{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOik1h6kkTdkpSMz5Jwz5c1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajinkyagh/Python_Practice/blob/main/Python_PySpark_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtUzEfvW4JLA",
        "outputId": "b9a1a90a-6129-4642-e7e6-db4a5d63ffe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+\n",
            "|   Name| Age|\n",
            "+-------+----+\n",
            "|  Alice|  25|\n",
            "|    Bob|  30|\n",
            "|Charlie|NULL|\n",
            "|   John|  30|\n",
            "+-------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#EDA & Data Manipulation\n",
        "#Creating a dataframe from List\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"EDA Methods\").getOrCreate()\n",
        "\n",
        "data = [(\"Alice\",25),(\"Bob\",30), (\"Charlie\", None ), (\"John\",30)]\n",
        "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read CSV file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "df_customers = spark.read.csv('/content/gdrive/My Drive/Colab Notebooks/dataset/customers.csv', header=True, inferSchema=True)\n",
        "df_customers.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRQop-sL5jgI",
        "outputId": "5e275a34-82ab-4ab1-a428-d6523b0b0667"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "+-----------+-------+-----------+------------------+\n",
            "|customer_id|   name|signup_date|             email|\n",
            "+-----------+-------+-----------+------------------+\n",
            "|          1|  Alice| 2021-01-01| user1@example.com|\n",
            "|          2|    Bob| 2021-04-01| user2@example.com|\n",
            "|          3|Charlie| 2021-06-30| user3@example.com|\n",
            "|          4|  David| 2021-09-28|              NULL|\n",
            "|          5|    Eva| 2021-12-27| user5@example.com|\n",
            "|          6|  Frank| 2022-03-27| user6@example.com|\n",
            "|          7|  Grace| 2022-06-25| user7@example.com|\n",
            "|          8|  Helen| 2022-09-23| user8@example.com|\n",
            "|          9|    Ian| 2022-12-22| user9@example.com|\n",
            "|         10|   Jane| 2023-03-22|user10@example.com|\n",
            "+-----------+-------+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read a parquet File into the a data frame\n",
        "# df_orders = spark.read.parquet('/content/gdrive/My Drive/Colab Notebooks/dataset/orders.csv')\n",
        "\n",
        "#Read a json File into the a data frame\n",
        "#df = spark.read.json(\"path\")"
      ],
      "metadata": {
        "id": "1dc0lpkx6WpJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic EDA Methods\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNkIJJya72MY",
        "outputId": "4d5b6f58-e3e1-46f5-e509-7ee2304702c7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+\n",
            "|   Name| Age|\n",
            "+-------+----+\n",
            "|  Alice|  25|\n",
            "|    Bob|  30|\n",
            "|Charlie|NULL|\n",
            "|   John|  30|\n",
            "+-------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF92r_o18tKx",
        "outputId": "cf41588b-7a47-4bd2-a2ed-fcd7a4dd8b41"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nQwefiG82qU",
        "outputId": "0314c5b1-36c4-453b-e77c-79460da8d629"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Displays the schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyO6R40885Ny",
        "outputId": "75637642-7d2a-42bc-d775-4d559533f331"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computes summary statistics for numerical columns.\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkgc90wg8_DW",
        "outputId": "6a9fea7b-cb2e-4d2b-b612-ed692f0427d7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+------------------+\n",
            "|summary| Name|               Age|\n",
            "+-------+-----+------------------+\n",
            "|  count|    4|                 3|\n",
            "|   mean| NULL|28.333333333333332|\n",
            "| stddev| NULL| 2.886751345948129|\n",
            "|    min|Alice|                25|\n",
            "|    max| John|                30|\n",
            "+-------+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Commutes column wise missing values.\n",
        "from pyspark.sql.functions import col,sum\n",
        "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peh_mL7-9QoQ",
        "outputId": "c2903718-ebaf-4ce7-c7b1-f63a39ef9990"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "|   0|  1|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering and Selecting Data\n",
        "df.show(5)\n",
        "\n",
        "#Filter rows where Age is greater than 25\n",
        "df.filter(df.Age > 25).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu1BD8B--HOT",
        "outputId": "c7799eea-0d98-450f-aaed-7b4ba2cb3e28"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+\n",
            "|   Name| Age|\n",
            "+-------+----+\n",
            "|  Alice|  25|\n",
            "|    Bob|  30|\n",
            "|Charlie|NULL|\n",
            "|   John|  30|\n",
            "+-------+----+\n",
            "\n",
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "| Bob| 30|\n",
            "|John| 30|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter using multiple conditions\n",
        "df.filter((df.Age>=25) & (df.Name.startswith(\"A\"))).show()\n",
        "\n",
        "df.filter((df.Age>=25) & (df.Name==\"Bob\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukNP54bICXYX",
        "outputId": "e2edc4db-dfa0-4024-be91-21a14e77c8e7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Alice| 25|\n",
            "+-----+---+\n",
            "\n",
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "| Bob| 30|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select Specific Columns\n",
        "df.select(\"Name\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgf4Zli0C91u",
        "outputId": "766535bf-b684-4540-a57c-4de4fdfae99d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|   Name|\n",
            "+-------+\n",
            "|  Alice|\n",
            "|    Bob|\n",
            "|Charlie|\n",
            "|   John|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add a new column\n",
        "from pyspark.sql.functions import lit\n",
        "df = df.withColumn(\"Country\", lit(\"USA\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDjBEgGJDYW8",
        "outputId": "d1320d92-b3f7-4df3-f202-1e73f4d1cf8a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-------+\n",
            "|   Name| Age|Country|\n",
            "+-------+----+-------+\n",
            "|  Alice|  25|    USA|\n",
            "|    Bob|  30|    USA|\n",
            "|Charlie|NULL|    USA|\n",
            "|   John|  30|    USA|\n",
            "+-------+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rename a column\n",
        "df = df.withColumnRenamed(\"Country\", \"Nationality\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIkamiZ5Dri2",
        "outputId": "83f840d9-c1da-4bbc-e713-7b5e76ec63d4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-----------+\n",
            "|   Name| Age|Nationality|\n",
            "+-------+----+-----------+\n",
            "|  Alice|  25|        USA|\n",
            "|    Bob|  30|        USA|\n",
            "|Charlie|NULL|        USA|\n",
            "|   John|  30|        USA|\n",
            "+-------+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop a column\n",
        "#df = df.drop(\"Nationality\")\n",
        "#df.show()"
      ],
      "metadata": {
        "id": "HPEeIAcyD7fX"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aggregations and Grouping\n",
        "#Counts the number of occurrences per category\n",
        "df.groupBy(\"Age\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ_Q9ZsZEDrK",
        "outputId": "2f629188-422c-4b5b-cdf7-41065ebdada9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| Age|count|\n",
            "+----+-----+\n",
            "|  25|    1|\n",
            "|  30|    2|\n",
            "|NULL|    1|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finds the average age per country\n",
        "df.groupBy(\"Nationality\").agg({\"Age\": \"avg\"}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrD52vfoFy30",
        "outputId": "51c0397b-b00f-4e49-b205-5d97f5d52985"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|Nationality|          avg(Age)|\n",
            "+-----------+------------------+\n",
            "|        USA|28.333333333333332|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computes multiple aggregations\n",
        "from pyspark.sql.functions import min, max, avg\n",
        "df.groupBy(\"Nationality\").agg(avg(\"Age\"), min(\"Age\"), max(\"Age\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFlPpyI1GkcV",
        "outputId": "994e1380-4215-4cdc-d324-1a0c832df4cc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+--------+--------+\n",
            "|Nationality|          avg(Age)|min(Age)|max(Age)|\n",
            "+-----------+------------------+--------+--------+\n",
            "|        USA|28.333333333333332|      25|      30|\n",
            "+-----------+------------------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting and Ranking\n",
        "#Sorts DatFrame in ascending order.\n",
        "df.show()\n",
        "\n",
        "df.orderBy(df.Age.asc()).show()"
      ],
      "metadata": {
        "id": "0CkFCesoHIxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015c3410-8091-4b7a-9e99-de5ec27b935b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-----------+\n",
            "|   Name| Age|Nationality|\n",
            "+-------+----+-----------+\n",
            "|  Alice|  25|        USA|\n",
            "|    Bob|  30|        USA|\n",
            "|Charlie|NULL|        USA|\n",
            "|   John|  30|        USA|\n",
            "+-------+----+-----------+\n",
            "\n",
            "+-------+----+-----------+\n",
            "|   Name| Age|Nationality|\n",
            "+-------+----+-----------+\n",
            "|Charlie|NULL|        USA|\n",
            "|  Alice|  25|        USA|\n",
            "|   John|  30|        USA|\n",
            "|    Bob|  30|        USA|\n",
            "+-------+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorts DatFrame in desc order.\n",
        "df.orderBy(df.Age.desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UdEPrXCRc1k",
        "outputId": "6334a6f2-1f11-456e-cf47-44d17b974975"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-----------+\n",
            "|   Name| Age|Nationality|\n",
            "+-------+----+-----------+\n",
            "|   John|  30|        USA|\n",
            "|    Bob|  30|        USA|\n",
            "|  Alice|  25|        USA|\n",
            "|Charlie|NULL|        USA|\n",
            "+-------+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ADDS a row number column(ranking)\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "windowSpec = Window.orderBy(\"Age\")\n",
        "df.withColumn(\"row_number\", row_number().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ito--fluR05R",
        "outputId": "7b834b2b-1d21-442c-fb82-7d67b8fdc664"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-----------+----------+\n",
            "|   Name| Age|Nationality|row_number|\n",
            "+-------+----+-----------+----------+\n",
            "|Charlie|NULL|        USA|         1|\n",
            "|  Alice|  25|        USA|         2|\n",
            "|    Bob|  30|        USA|         3|\n",
            "|   John|  30|        USA|         4|\n",
            "+-------+----+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling Missing Data\n",
        "#Drops rows with any null values\n",
        "df.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bbgOldeSRev",
        "outputId": "3687b3de-b4aa-4cfe-a095-37ecd877f1f6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-----------+\n",
            "| Name|Age|Nationality|\n",
            "+-----+---+-----------+\n",
            "|Alice| 25|        USA|\n",
            "|  Bob| 30|        USA|\n",
            "| John| 30|        USA|\n",
            "+-----+---+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fills null values with a default value.\n",
        "df.na.fill({\"Age\": 30}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKFpD8HPS49v",
        "outputId": "5e818b13-edd4-46c5-df0e-6bab4a7477cb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+-----------+\n",
            "|   Name|Age|Nationality|\n",
            "+-------+---+-----------+\n",
            "|  Alice| 25|        USA|\n",
            "|    Bob| 30|        USA|\n",
            "|Charlie| 30|        USA|\n",
            "|   John| 30|        USA|\n",
            "+-------+---+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replaces specific values.\n",
        "df = df.replace(\"USA\", \"United States\")"
      ],
      "metadata": {
        "id": "_kxcvfA1TMtN"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhWwXJzfU_CB",
        "outputId": "c1604845-df50-4e66-b0ae-ead17c71728c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-------------+\n",
            "|   Name| Age|  Nationality|\n",
            "+-------+----+-------------+\n",
            "|  Alice|  25|United States|\n",
            "|    Bob|  30|United States|\n",
            "|Charlie|NULL|United States|\n",
            "|   John|  30|United States|\n",
            "+-------+----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "l6vF4ItZVk3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Conditional Logic\n",
        "#Assigns categories based on age.\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "df.withColumn(\"Age_Category\", when(df.Age < 18, \"Child\").when(df.Age <=25 , \"Middle-Aged\").otherwise(\"Senior\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jIGDUdHVFLf",
        "outputId": "13da94da-9c0d-43cc-c07b-5481a9bdf00c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-------------+------------+\n",
            "|   Name| Age|  Nationality|Age_Category|\n",
            "+-------+----+-------------+------------+\n",
            "|  Alice|  25|United States| Middle-Aged|\n",
            "|    Bob|  30|United States|      Senior|\n",
            "|Charlie|NULL|United States|      Senior|\n",
            "|   John|  30|United States|      Senior|\n",
            "+-------+----+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#String Functions\n",
        "#Concatenates first and last names\n",
        "from pyspark.sql.functions import concat, lit\n",
        "\n",
        "df.withColumn(\"Full_Name\", concat(df.Name, lit(\" Tendulkar\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOFsWXccYdtR",
        "outputId": "e906c288-c5f5-4c15-b694-d8951a59b6f1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-------------+-----------------+\n",
            "|   Name| Age|  Nationality|        Full_Name|\n",
            "+-------+----+-------------+-----------------+\n",
            "|  Alice|  25|United States|  Alice Tendulkar|\n",
            "|    Bob|  30|United States|    Bob Tendulkar|\n",
            "|Charlie|NULL|United States|Charlie Tendulkar|\n",
            "|   John|  30|United States|   John Tendulkar|\n",
            "+-------+----+-------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converts text to lowercase\n",
        "from pyspark.sql.functions import lower\n",
        "\n",
        "df.withColumn(\"Name\", lower(df.Name)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SdNjhAqZodW",
        "outputId": "48b02a69-2dbf-4420-b04f-68b9e288667d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-------------+\n",
            "|   Name| Age|  Nationality|\n",
            "+-------+----+-------------+\n",
            "|  alice|  25|United States|\n",
            "|    bob|  30|United States|\n",
            "|charlie|NULL|United States|\n",
            "|   john|  30|United States|\n",
            "+-------+----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove whitespace from strings.\n",
        "from pyspark.sql.functions import trim\n",
        "\n",
        "df.withColumn(\"Name\", trim(df.Name)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4ocZ6uKaTog",
        "outputId": "8f0db2ff-dbcb-4868-e0f5-f9bff16249e6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-------------+\n",
            "|   Name| Age|  Nationality|\n",
            "+-------+----+-------------+\n",
            "|  Alice|  25|United States|\n",
            "|    Bob|  30|United States|\n",
            "|Charlie|NULL|United States|\n",
            "|   John|  30|United States|\n",
            "+-------+----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MATHEMATICAL functions\n",
        "#Rounds a number\n",
        "from pyspark.sql.functions import round\n",
        "\n",
        "df.withColumn(\"Age_Rounded\", round(df.Age, 0)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHQ0eR_BcWHk",
        "outputId": "9f0b26cc-bb57-4c8a-a4c7-6006cf6eaff7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+-------------+-----------+\n",
            "|   Name| Age|  Nationality|Age_Rounded|\n",
            "+-------+----+-------------+-----------+\n",
            "|  Alice|  25|United States|         25|\n",
            "|    Bob|  30|United States|         30|\n",
            "|Charlie|NULL|United States|       NULL|\n",
            "|   John|  30|United States|         30|\n",
            "+-------+----+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add some values data to data\n",
        "data.append([\"Victoria\",40])\n",
        "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoUUtQaTc6S_",
        "outputId": "6ea65111-574e-4985-a6d2-3e3b7c08eb0e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+\n",
            "|    Name| Age|\n",
            "+--------+----+\n",
            "|   Alice|  25|\n",
            "|     Bob|  30|\n",
            "| Charlie|NULL|\n",
            "|    John|  30|\n",
            "|Victoria|  40|\n",
            "|Victoria|  40|\n",
            "+--------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add nationality\n",
        "df = df.withColumn(\"Nationality\", lit(\"Australia\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKNjRljbeByT",
        "outputId": "1568b54a-b21d-45ed-b43a-ad07c979711f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+\n",
            "|    Name| Age|Nationality|\n",
            "+--------+----+-----------+\n",
            "|   Alice|  25|  Australia|\n",
            "|     Bob|  30|  Australia|\n",
            "| Charlie|NULL|  Australia|\n",
            "|    John|  30|  Australia|\n",
            "|Victoria|  40|  Australia|\n",
            "|Victoria|  40|  Australia|\n",
            "+--------+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computes the square root\n",
        "from pyspark.sql.functions import sqrt\n",
        "\n",
        "df.withColumn(\"Age_sqrt\", sqrt(df.Age)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5BPRCa9eVP4",
        "outputId": "8e5dc717-5924-47f1-d1c3-fd6fdb0aa894"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+-----------------+\n",
            "|    Name| Age|Nationality|         Age_sqrt|\n",
            "+--------+----+-----------+-----------------+\n",
            "|   Alice|  25|  Australia|              5.0|\n",
            "|     Bob|  30|  Australia|5.477225575051661|\n",
            "| Charlie|NULL|  Australia|             NULL|\n",
            "|    John|  30|  Australia|5.477225575051661|\n",
            "|Victoria|  40|  Australia|6.324555320336759|\n",
            "|Victoria|  40|  Australia|6.324555320336759|\n",
            "+--------+----+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computes Logarithm\n",
        "from pyspark.sql.functions import log\n",
        "\n",
        "df.withColumn(\"Age_log\", log(df.Age)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGwVdl0pelty",
        "outputId": "92e0d39e-704a-4165-e6fd-c304c12479ab"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+------------------+\n",
            "|    Name| Age|Nationality|           Age_log|\n",
            "+--------+----+-----------+------------------+\n",
            "|   Alice|  25|  Australia|3.2188758248682006|\n",
            "|     Bob|  30|  Australia|3.4011973816621555|\n",
            "| Charlie|NULL|  Australia|              NULL|\n",
            "|    John|  30|  Australia|3.4011973816621555|\n",
            "|Victoria|  40|  Australia|3.6888794541139363|\n",
            "|Victoria|  40|  Australia|3.6888794541139363|\n",
            "+--------+----+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Date & Time Functions\n",
        "#Gets the current date\n",
        "\n",
        "from pyspark.sql.functions import current_date\n",
        "\n",
        "df.withColumn(\"Current_Date\", current_date()).show()\n",
        "df = df.withColumn(\"Current_Date\", current_date())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub1r0OufevV9",
        "outputId": "40c7f1b0-a09e-44a5-db5b-40b04e8be3db"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+------------+\n",
            "|    Name| Age|Nationality|Current_Date|\n",
            "+--------+----+-----------+------------+\n",
            "|   Alice|  25|  Australia|  2025-08-21|\n",
            "|     Bob|  30|  Australia|  2025-08-21|\n",
            "| Charlie|NULL|  Australia|  2025-08-21|\n",
            "|    John|  30|  Australia|  2025-08-21|\n",
            "|Victoria|  40|  Australia|  2025-08-21|\n",
            "|Victoria|  40|  Australia|  2025-08-21|\n",
            "+--------+----+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gets current time stamp\n",
        "from pyspark.sql.functions import current_timestamp\n",
        "\n",
        "df.withColumn(\"Current_Timestamp\", current_timestamp()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7xlDmDigR_V",
        "outputId": "dad6ea49-5b8d-46e8-fc2f-332f667111f3"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+------------+--------------------+\n",
            "|    Name| Age|Nationality|Current_Date|   Current_Timestamp|\n",
            "+--------+----+-----------+------------+--------------------+\n",
            "|   Alice|  25|  Australia|  2025-08-21|2025-08-21 16:42:...|\n",
            "|     Bob|  30|  Australia|  2025-08-21|2025-08-21 16:42:...|\n",
            "| Charlie|NULL|  Australia|  2025-08-21|2025-08-21 16:42:...|\n",
            "|    John|  30|  Australia|  2025-08-21|2025-08-21 16:42:...|\n",
            "|Victoria|  40|  Australia|  2025-08-21|2025-08-21 16:42:...|\n",
            "|Victoria|  40|  Australia|  2025-08-21|2025-08-21 16:42:...|\n",
            "+--------+----+-----------+------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracts year from a date column\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "df.withColumn(\"Year\", year(df.Current_Date)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX5V7bmDgbeD",
        "outputId": "49eb97a5-9b04-4a16-d2a6-57c3c2975f75"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+------------+----+\n",
            "|    Name| Age|Nationality|Current_Date|Year|\n",
            "+--------+----+-----------+------------+----+\n",
            "|   Alice|  25|  Australia|  2025-08-21|2025|\n",
            "|     Bob|  30|  Australia|  2025-08-21|2025|\n",
            "| Charlie|NULL|  Australia|  2025-08-21|2025|\n",
            "|    John|  30|  Australia|  2025-08-21|2025|\n",
            "|Victoria|  40|  Australia|  2025-08-21|2025|\n",
            "|Victoria|  40|  Australia|  2025-08-21|2025|\n",
            "+--------+----+-----------+------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector Assembler\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols=[\"Age\"], outputCol=\"features\", handleInvalid=\"keep\")\n",
        "df_assembler = assembler.transform(df)\n",
        "df_assembler.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PJxn7C5goL9",
        "outputId": "88c1fbf2-ee5b-4f3f-96b3-77a73dba565c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+------------+--------+\n",
            "|    Name| Age|Nationality|Current_Date|features|\n",
            "+--------+----+-----------+------------+--------+\n",
            "|   Alice|  25|  Australia|  2025-08-21|  [25.0]|\n",
            "|     Bob|  30|  Australia|  2025-08-21|  [30.0]|\n",
            "| Charlie|NULL|  Australia|  2025-08-21|   [NaN]|\n",
            "|    John|  30|  Australia|  2025-08-21|  [30.0]|\n",
            "|Victoria|  40|  Australia|  2025-08-21|  [40.0]|\n",
            "|Victoria|  40|  Australia|  2025-08-21|  [40.0]|\n",
            "+--------+----+-----------+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7465e57e"
      },
      "source": [
        "**Vector Assembler:**\n",
        "\n",
        "A Vector Assembler is a transformer that combines a given list of numerical columns into a single vector column. This is often used as a preparatory step for machine learning models that require a single feature vector input."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "# Drop rows with nulls in the 'Age' column (the label column)\n",
        "df_cleaned = df_assembler.na.drop(subset=[\"Age\"])\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Age\")\n",
        "lr_model = lr.fit(df_cleaned)"
      ],
      "metadata": {
        "id": "Nlx1vBVklikN"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Intercept:\", lr_model.intercept)\n",
        "print(\"Coefficients:\", lr_model.coefficients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMvNFE5zmbj8",
        "outputId": "5fc16aef-3fd1-4b58-97b9-8a606eb881ba"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: 1.6653345369377333e-13\n",
            "Coefficients: [0.9999999999999949]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline for ML Modeling\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Drop rows with nulls in the 'Age' column before fitting the pipeline\n",
        "df_cleaned_for_pipeline = df.na.drop(subset=[\"Age\"])\n",
        "\n",
        "pipeline = Pipeline(stages=[assembler, lr])\n",
        "pipeline_model = pipeline.fit(df_cleaned_for_pipeline)"
      ],
      "metadata": {
        "id": "_2VRhYR4nyV_"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cache and Persist\n",
        "#Caches DataFrame in memory for faster access.\n",
        "df.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8_XoYP76Jy2",
        "outputId": "bca7d774-b6e3-4381-b7a6-4b3df4bf992d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Age: bigint, Nationality: string, Current_Date: date]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Persists DataFrame to memory/disk\n",
        "from pyspark.storagelevel import StorageLevel\n",
        "df.persist(StorageLevel.MEMORY_AND_DISK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh7n5rRP7k3l",
        "outputId": "107713ce-f805-4cdf-aecc-0a324b8cbdd4"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Age: bigint, Nationality: string, Current_Date: date]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unpersists the DataFrame\n",
        "df.unpersist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzqbmprm77CE",
        "outputId": "b212d312-a7f2-4bac-bb6d-250c4d3d1e7b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Age: bigint, Nationality: string, Current_Date: date]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Repartioning and Coalescing\n",
        "#Increase the number of partitions.\n",
        "df.repartition(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aIM6HKd8BOb",
        "outputId": "e60a053c-16d9-4089-e79f-c56a229c2460"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Age: bigint, Nationality: string, Current_Date: date]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reduce Partitions\n",
        "df.coalesce(2)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvZrENMy_FHB",
        "outputId": "a112f8da-d41e-4067-c8e8-1f425a77ef97"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+------------+\n",
            "|    Name| Age|Nationality|Current_Date|\n",
            "+--------+----+-----------+------------+\n",
            "|   Alice|  25|  Australia|  2025-08-21|\n",
            "|     Bob|  30|  Australia|  2025-08-21|\n",
            "| Charlie|NULL|  Australia|  2025-08-21|\n",
            "|    John|  30|  Australia|  2025-08-21|\n",
            "|Victoria|  40|  Australia|  2025-08-21|\n",
            "|Victoria|  40|  Australia|  2025-08-21|\n",
            "+--------+----+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Explaining Query Execution\n",
        "df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGQDYxr__OJ7",
        "outputId": "850f5d67-33a5-45f5-8a8d-7acdcad9c8ce"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Project [Name#1588, Age#1589L, Nationality#1601, current_date(None) AS Current_Date#1728]\n",
            "+- Project [Name#1588, Age#1589L, Australia AS Nationality#1601]\n",
            "   +- LogicalRDD [Name#1588, Age#1589L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "Name: string, Age: bigint, Nationality: string, Current_Date: date\n",
            "Project [Name#1588, Age#1589L, Nationality#1601, current_date(Some(Etc/UTC)) AS Current_Date#1728]\n",
            "+- Project [Name#1588, Age#1589L, Australia AS Nationality#1601]\n",
            "   +- LogicalRDD [Name#1588, Age#1589L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [Name#1588, Age#1589L, Australia AS Nationality#1601, 2025-08-21 AS Current_Date#1728]\n",
            "+- LogicalRDD [Name#1588, Age#1589L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [Name#1588, Age#1589L, Australia AS Nationality#1601, 2025-08-21 AS Current_Date#1728]\n",
            "+- *(1) Scan ExistingRDD[Name#1588,Age#1589L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Streaming methods\n",
        "#Reading Streaming Methods\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Streaming\").getOrCreate()\n",
        "\n",
        "df1 = spark.readStream.format(\"socket\").option(\"host\", \"localhost\").option(\"port\", \"9999\").load()"
      ],
      "metadata": {
        "id": "6ACa0we4_w0X"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Writing Streaming Data to Console\n",
        "df1.writeStream.outputMode(\"append\").format(\"console\").start().awaitTermination()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "S0Hn30VYB9dn",
        "outputId": "0ee321b8-8a0b-490d-98fe-64790279c347"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StreamingQueryException",
          "evalue": "[STREAM_FAILED] Query [id = 297d0740-270a-451d-9104-ad147c36d75b, runId = 56b9d4ab-9cad-49ac-96de-1bd1dd414204] terminated with exception: Connection refused (Connection refused)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStreamingQueryException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1347421518.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Writing Streaming Data to Console\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"append\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"console\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/streaming/query.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStreamingQueryException\u001b[0m: [STREAM_FAILED] Query [id = 297d0740-270a-451d-9104-ad147c36d75b, runId = 56b9d4ab-9cad-49ac-96de-1bd1dd414204] terminated with exception: Connection refused (Connection refused)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RDD Methods\n",
        "#Creating an RDD\n",
        "rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n",
        "\n",
        "#RDD Transformations\n",
        "#Doubles each element in RDD\n",
        "rdd.map(lambda x: x * 2).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RT4ZqfRB6yI",
        "outputId": "b3c9bee5-ad3c-4acd-c817-98bb868ddcfd"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filters elements greater than 2.\n",
        "rdd.filter(lambda x: x > 2).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q4P9gyyF2dN",
        "outputId": "22517540-88fc-4960-cbe1-1b624a40ba07"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e81ce28d"
      },
      "source": [
        "**Exact Use of RDDs:**\n",
        "\n",
        "RDDs (Resilient Distributed Datasets) were the primary API in earlier versions of Spark. They are immutable, fault-tolerant, and distributed collections of objects that can be processed in parallel. While newer APIs like DataFrames and Datasets are often preferred for their optimizations and ease of use, RDDs are still valuable for:\n",
        "\n",
        "*   **Low-level transformations and control:** When you need to perform transformations that are not easily expressed with DataFrames/Datasets or require fine-grained control over partitioning.\n",
        "*   **Working with unstructured data:** RDDs are suitable for processing data that doesn't fit into a structured schema.\n",
        "*   **Maintaining backward compatibility:** If you have existing Spark applications built with RDDs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RDD Actions\n",
        "#Count elements.\n",
        "rdd.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbJcOZ9wGF-e",
        "outputId": "659edab7-4c0b-4035-fa96-caa483cfefc2"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finds the max value\n",
        "rdd.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4huEW8DGjZp",
        "outputId": "90e07c1d-3000-4e73-a0ea-bc228f56d399"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Collects all elements.\n",
        "rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s7Hg14aGrN1",
        "outputId": "6183c8f5-c400-493c-b83c-3aaa96ac5307"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJhEcbB6GvH3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}